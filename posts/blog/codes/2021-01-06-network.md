---
title: "计算机网络"
author: [Sylvenas]
categories: 'network'
img: './img/2015-03-25.jpg'
secert: true
---

## 三次握手与四次挥手
客户端首先会发起一个带SYN标志的数据包给服务端，表示客户端向服务端发起连接请求，服务端收到之后，回传一个ACK(表示准许这个连接)和SYN(表示服务端向客户端发连接请求)，客户端收到之后，传递ACK(表示准许这次连接)给服务端。

### 为什么需要三次握手
[为什么需要三次握手？而不是两次或者四次](https://networkengineering.stackexchange.com/questions/24068/why-do-we-need-a-3-way-handshake-why-not-just-2-way)一句话描述：因为需要传递双方的ISN(Initial Sequence Number)


在TCP中，双方通过使用一个序列号来跟踪他们所发送的内容。有效地，它最终成为所有发送内容的运行字节数。接收方可以使用对方的序列号来确认它所收到的信息。序列号不是从0开始，而是从ISN（初始序列号）开始，这是一个随机选择的值。由于TCP是双向通信，双方都可以 "说话"，因此都必须随机生成一个ISN作为他们的起始序列号。这反过来意味着，双方都需要通知对方他们的起始ISN。

因此，对于Alice和Bob之间的TCP对话的开始，你最终会得到这样的事件序列。

```
Alice ---> Bob    SYNchronize with my Initial Sequence Number of X
Alice <--- Bob    I received your syn, I ACKnowledge that I am ready for [X+1]
Alice <--- Bob    SYNchronize with my Initial Sequence Number of Y
Alice ---> Bob    I received your syn, I ACKnowledge that I am ready for [Y+1]
```

注意，有四个事件正在发生。

- Alice选择了一个ISN并与Bob同步。
- 鲍勃知道了这个ISN。
- 鲍勃选择了一个ISN，并与爱丽丝进行了同步。

但实际上，中间的两个事件（#2和#3）发生在同一个数据包中。使数据包成为SYN或ACK的原因只是在每个TCP头内打开或关闭的一个二进制标志，所以没有任何东西可以阻止这些标志在同一个数据包中被启用。因此，三方握手的结果是。

```
Bob <--- Alice     SYN
Bob ---> Alice     SYN ACK 
Bob <--- Alice     ACK     
```

> Notice the two instances of "SYN" and "ACK", one of each, in both directions.

### 为什么需要四次握手
[为什么需要四次挥手?而不是两次，三次](https://stackoverflow.com/questions/46212623/why-tcp-connect-termination-need-4-way-handshake)

实际上四次握手可以分解为两队双向握手，因为TCP为全双工通信，在第一对握手中，client 像 server 发出断开链接的请求，服务端回复允许断开链接

```
Client ------FIN-----> Server

Client <-----ACK------ Server
```

此刻，客户端一直处于FIN_WAIT_2状态，等待服务器的FIN。作为一个双向和全双工的协议，目前 client 已经中断，没有更多的数据会被发送，但server仍然工作，客户端必须等待另一个 "半双工 "被终止。

当服务器的FIN被发送到客户端时，客户端响应一个ACK来终止连接。

```
Server ------FIN-----> Client

Server <-----ACK------ Client
```

总结：2和3不能合并成一个包，因为它们属于不同的状态。但是，如果服务器在收到客户端的FIN后，没有更多的数据或根本没有数据要发送，那么将2和3合并为一个包就可以了。

所以断开链接的四次握手，在某些情况下可能合并一个包为三次握手

## http 1/2/3

- HTTP/1.x 有连接无法复用、队头阻塞、协议开销大和安全因素等多个缺陷
- HTTP/2 通过多路复用、二进制流、Header 压缩等等技术，极大地提高了性能，但是还是存在着问题的(队头阻塞,tcp链接握手延迟大等，依赖于操作系统的实现导致协议本身僵化)
- QUIC 基于 UDP 实现，是 HTTP/3 中的底层支撑协议，该协议基于 UDP，又取了 TCP 中的精华，实现了即快又可靠的协议

### http1的缺陷
#### 连接无法复用
连接无法复用会导致每次请求都经历三次握手和慢启动

- HTTP/1.0 传输数据时，每次都需要重新建立连接，增加延迟
- HTTP/1.1 虽然加入 keep-alive 可以复用一部分连接，但域名分片等情况下仍然需要建立多个 connection，耗费资源，给服务器带来性能压力。

#### Head-Of-Line Blocking(队头阻塞)
HOLB是指一系列包（package）因为第一个包(也有可能是前几个)被阻塞；当页面中需要请求很多资源的时候，HOLB（队头阻塞）会导致在达到最大请求数量时，剩余的资源需要等待其他资源请求完成后才能发起请求。

- HTTP 1.0：下个请求必须在前一个请求返回后才能发出，request-response对按序发生。显然，如果某个请求长时间没有返回，那么接下来的请求就全部阻塞了。
- HTTP 1.1：尝试使用 pipeling 来解决，即浏览器可以一次性发出多个请求（同个域名，同一条 TCP 链接）。但 pipeling 要求返回是按序的，那么前一个请求如果很耗时（比如处理大图片），那么后面的请求即使服务器已经处理完，仍会等待前面的请求处理完才开始按序返回。所以，pipeling 只部分解决了 HOLB。

#### 协议开销大
 HTTP1.x 在使用时，header 里携带的内容过大，在一定程度上增加了传输的成本，并且每次请求 header 基本不怎么变化，尤其在移动端增加用户流量。

### HTTP/2 新特性
#### 二进制传输与分帧层
HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。

- 流：流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）；
- 消息：是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。
- 帧：HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流，承载着特定类型的数据，如 HTTP 首部、负荷，等等，多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。

#### 多路复用
多路复用很好的解决了浏览器限制同一个域名下的请求数量的问题，同时也接更容易实现全速传输，毕竟新开一个 TCP 连接都需要慢慢提升传输速度。

- 同个域名只需要占用一个 TCP 连接，同域名下所有通信都在单个连接上完成。消除了 HTTP1 因多个 TCP 连接而带来的延时和内存消耗。
- 并行交错地发送多个请求/响应，请求之间互不影响。
- 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。

#### Header 压缩
- HTTP/2 在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；
- 首部表在 HTTP/2 的连接存续期内始终存在，由客户端和服务器共同渐进地更新;
- 每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值

#### Server Push
服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 时再发送这些请求。

> 在浏览器兼容的情况下你也可以使用 prefetch。

### http3

- 减少了 TCP 三次握手及 TLS 握手时间。
- 改进的拥塞控制。
- 避免队头阻塞的多路复用。
- 连接迁移。
- 前向冗余纠错。

上文提到 HTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。但当这个连接中出现了丢包的情况，那就会导致 HTTP/2 的表现情况反倒不如 HTTP/1 了，因为在出现丢包的情况下，整个 TCP 都要开始等待重传，会一直阻塞

> 有人考虑到去修改 TCP 协议，其实这已经是一件不可能完成的任务了。因为 TCP 存在的时间实在太长，已经充斥在各种设备中，并且这个协议是由操作系统实现的，更新起来不大现实。

**Google 就更起炉灶搞了一个基于 `UDP` 协议的 `QUIC` 协议，并且使用在了 HTTP/3 上**

#### 0-RTT
通过使用类似 TCP 快速打开的技术，缓存当前会话的上下文，在下次恢复会话的时候，只需要将之前的缓存传递给服务端验证通过就可以进行传输了。0RTT 建连可以说是 QUIC 相比 HTTP2 最大的性能优势

#### 多路复用

虽然 HTTP/2 支持了多路复用，但是 TCP 协议终究是没有这个功能的。QUIC 原生就实现了这个功能，并且传输的单个数据流可以保证有序交付且不会影响其他的数据流，这样的技术就解决了之前 TCP 存在的问题。

同 HTTP2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求，但是，**QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖**。比如下图中 stream2 丢了一个 UDP 包，不会影响后面跟着 Stream3 和 Stream4，不存在 TCP 队头阻塞。虽然 stream2 的那个包需要重新传，但是 stream3、stream4 的包无需等待，就可以发给用户。

#### 加密认证的报文
TCP 协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改，注入和窃听。比如修改序列号、滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。

但是 QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。

#### 向前纠错机制
QUIC 协议有一个非常独特的特性，称为向前纠错 (Forward Error Correction，FEC)，每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为丢包导致的数据重传，因为数据重传将会消耗更多的时间(包括确认数据包丢失、请求重传、等待新数据包等步骤的时间消耗)

假如说这次我要发送三个包，那么协议会算出这三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。当出现其中的非校验包丢包的情况时，可以通过另外三个包计算出丢失的数据包的内容。当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包就不能使用纠错机制了，只能使用重传的方式了。


#### 可插拔
应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，这在产品快速迭代，网络爆炸式增长的今天，显然有点满足不了需求。

## cache
html文件采用no-cache，一直走协商缓存
js,css,img,font使用max-age，走强缓存+协商缓存

- 强制缓存优先于协商缓存进行
- 若强制缓存( Expires 和 Cache-Control 时间决定 )生效则直接使用缓存
- 若不生效则进行协商缓存( Last-Modified/If-Modified-Since 和 Etag/If-None-Match )，协商缓存由服务器决定是否使用缓存，若协商缓存失效，那么代表该请求的缓存失效，重新获取请求，返回200，然后再存入浏览器缓存中
- 生效则返回 304，继续使用缓存，主要过程如下：

![](https://sylvenas.github.io/static/a4fc31c39882bae34205e12dfe6c9975/b4472/http-cache-all.png)


- no-cache：在发布缓存副本之前，强制要求缓存把请求提交给原始服务器进行验证(协商缓存验证)。（url 不变，但是内容可能变更，使用范围较小）
- no-store：缓存不应存储有关客户端请求或服务器响应的任何内容，即不使用任何缓存。
- private：表明响应只能被单个用户缓存，不能作为共享缓存（即代理服务器不能缓存它）。私有缓存可以缓存响应内容，比如：对应用户的本地浏览器。
- public：表明响应可以被任何对象（包括：发送请求的客户端，代理服务器，等等）缓存
- max-age = xxxxseconds：设置缓存存储的最大周期，超过这个时间缓存被认为过期(单位秒)。与Expires相反，时间是相对于请求的时间。（适用于内容不会变更，但是URl变更，比如重新打包之后的js，使用hash后缀）
- s-maxage:仅适用于共享缓存(比如各个代理)，私有缓存会忽略它

- must-revalidate:一旦资源过期，在成功向原始服务器验证之前，不能使用缓存

> 同时存在no-cache和max-age，则在强缓存时间内，依然会走强缓存


### CDN与缓存
- 源站设置了缓存规则
  - 源站设置了cache-control:no-cache/no-store
    - CND 未设置，则遵循源站的缓存规则。即CDN节点不缓存源站资源，用户每次访问都需要回源，无法实现加速
  - 源站**未设置** cache-control:no-cache/no-store
    - CND 设置了缓存规则，遵循CDN缓存规则
    - CND 未设置缓存规则，遵循源站的其他缓存规则

- 源站未设置缓存规则
  - CND 设置了缓存规则，遵循CDN缓存规则
  - CND 未设置缓存规则，遵循CDN默认缓存规则

> 当我们必须要在缓存期内修改文件，并且不向想影响用户体验，那么我们可以使用cdn服务商提供的强制更新缓存功能，这里的强制更新是更新CDN缓存，一般CDN服务商也会提供[API](https://help.aliyun.com/document_detail/27140.html)，直接调用来完成刷新和预热，

![](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/1313257261/p67212.png)


## DNS与CDN加速
DNS基于UDP

DNS解析步骤

- 先查询本机hosts文件映射；
- 查询本地DNS缓存(比如浏览器缓存)；
- 委托LSP-DNS查询（这个步骤也称递归查询）；
- LSP-DNS 做迭代查询；
- LSP-DNS将查询结果返回到本机；

#### 递归查询
主机向本地域名服务器的查询一般都是采用 递归查询 ： 如果主机所询问的本地域名服务器不知道被查询的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文（替该主机继续查询），而不是让该主机自己进行下一步的查询。因此，递归查询返回的查询结果或者是所要查询的IP，或者是报错，表示无法查询到所需的IP。

#### 迭代查询
本地域名服务器向根域名服务器的查询通常采用 迭代查询 ：当根服务器收到本地发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪个域名服务器查询。
然后本地域名服务器进行后续查询。根域名服务器通常把自己知道的顶级域名服务器告诉本地域名服务器，本地域名服务器再去顶级域名服务器查询...

### CDN加速
域名解析
解析域名分为两种：
- 将一个域名解析为一个IP地址
- 将一个域名解析为另外一个域名

其实解析思路不难，我们在域名服务商购买了一个域名之后，需要去映射一个 IP 地址，可以用 Map 来表示这个关系：`{域名：IP}`。
同时我们也可以给某个域名取一个别名，比如 “www.baidu.com” 取一个别名 “test.baidu.com” ，这种关系也可以用 Map 来表示：`{域名：别名}`。这里的别名专业一点叫做 `CNAME`，相信大家对这个词有点眼熟，它就是这个意思。

**域名解析，实际上就是解析出指定域名所对应的 IP 地址，或者该域名的一个 CNAME**。

CNAME是随便起的吗？很明显不是！[在开启CDN加速域名之后，CDN服务商会自动提供一个CNAME](https://help.aliyun.com/document_detail/27144.html),**我们需要在域名解析服务商处将加速域名的DNS解析记录指向CNAME域名，访问请求才能转发到CDN节点上，实现CDN加速**

域名解析是由DNS系统来负责的，DNS服务接受外部请求，从请求里提取域名，

- 如果这个域名对应的是IP地址，则返回这个IP地址，
- 如果这个域名对应的是CNAME，则继续查找CNAME域名的IP地址，然后将该地址返回给请求发送者。

在有CNAME的情况下，我们可以发现，CNAME实际上在域名解析的过程中承担了中间人（或者说代理）的角色，这是CDN实现的关键

用户在访问静态资源时也是通过域名来访问的，域名会被解析成某一个IP地址，关键的问题就是，DNS系统怎么在做域名解析时，解析出来一个离用户最近的一个IP地址呢。

普通的DNS系统是做不到的，需要一个特殊的DNS服务器，这个特殊DNS需要知道

第一个问题好解决，直接从用户请求里提取出用户的ip地址，比如这个ip地址被解析为北京电信、上海移动等等。
第二个问题由谁来解决，我们现在考虑的是CDN，CDN提供商肯定知道他们公司在哪些地方部署了机器以及它们的IP地址，所以这个问题只能有CDN提供商来解决，**CDN提供商会提供这个特殊的DNS服务器，我们叫做 CDN专用DNS服务器**。

用户使用某个域名来访问静态资源时（这个域名在阿里CDN服务中叫做“加速域名”），比如这个域名为“image.baidu.com”，它对应一个CNAME，叫做“cdn.ali.com”，那么普通DNS服务器（区别CDN专用DNS服务器）在解析“image.baidu.com”时，会先解析成“cdn.ali.com”，普通DNS服务器发现该域名对应的也是一个DNS服务器，那么会将域名解析工作转交给该DNS服务器，该DNS服务器就是CDN专用DNS服务器。CDN专用DNS服务器对“cdn.ali.com”进行解析，然后依据服务器上记录的所有CDN服务器地址信息，选出一个离用户最近的一个CDN服务器地址，并返回给用户，用户即可访问离自己最近的一台CDN服务器了。

## cors
### 简单请求
同时满足以下两个条件
1.请求方法
- HEAD
- GET
- POST

2.HTTP的头信息不超出以下几种字段：
- Accept
- Accept-Language
- Content-Language
- Last-Event-ID
- Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain

浏览器在发起请求的时候会携带 origin header,服务端判定是否在许可范围内，如果是，则 response 中包含`Access-Control-Allow-Origin`，浏览器会识别该字段准许通行，否则抛出错误

### 非简单请求
1.请求方法
- PUT
- DELETE

2.HTTP的头以下几种字段：
- Content-Type：application/json

非简单请求的CORS请求，会在正式通信之前，增加一次 HTTP 查询请求，称为"预检"请求（preflight）。

"预检"请求用的请求方法是 `OPTIONS`，表示这个请求是用来询问的。头信息里面，关键字段是 `Origin`，表示请求来自哪个源。


服务器收到"预检"请求以后，检查了 `Origin`、`Access-Control-Request-Method` 和`Access-Control-Request-Headers` 字段以后，确认允许跨源请求，就可以做出回应

如果服务器否定了"预检"请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。

一旦服务器通过了"预检"请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。

